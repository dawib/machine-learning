{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Mając do dyspozycji dane dotyczące raka piersi, stwórz optymalny model objaśniająycy zmienną \"target\". \n",
    "Całą pracę rozpocznij od oddzielenia losowo wybranych  $20\\%$ danych. Następnie pracuj na pozostałych  $80\\%$  danych. \n",
    "Zdecyduj jak przygotować dane i które zmienne brać pod uwagę. Przy pomocy testowania krzyżowego znajdź najlepsze parametry. \n",
    "Na końcu sprawdź działanie modelu na wcześniej oddzielonych $20\\%$  danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant', 'benign']\n",
      "['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
      "(569, 30)\n",
      "Regresja bez regularyzacji:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93        48\n",
      "           1       0.92      1.00      0.96        66\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.96      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Regresja z regularyzacją:\n",
      "C: 2.03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93        48\n",
      "           1       0.92      1.00      0.96        66\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.96      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Maszyna wektorów nośnych:\n",
      "{'C': 1.6410204081632653, 'gamma': 0.21387755102040817}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93        48\n",
      "           1       0.94      0.95      0.95        66\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.94      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report as CR\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "data = load_breast_cancer()\n",
    "print(list(data.target_names))\n",
    "print(list(data.feature_names))\n",
    "print((data.data).shape)\n",
    "X=data.data\n",
    "y=data.target\n",
    "\n",
    "Xp = np.hsplit(X,np.array([10,40]))[0] #bierzemy pierwsze 10 kolumn, ponieważ kolejne to błędy pomiarowe i pochodne wcześniejszych\n",
    "Xp_train, Xp_test, y_train, y_test = train_test_split(Xp,y,test_size=.2)\n",
    "Xps_train = scale(Xp_train)\n",
    "Xps_test = scale(Xp_test)\n",
    "XX_train, XX_test = Xps_train, Xps_test\n",
    "\n",
    "#regresja logistyczna---------------------------------------------------------------------------------------\n",
    "model_reg_nopen = lm.LogisticRegression(penalty='none').fit(XX_train,y_train)\n",
    "y_pred_reg_nopen = model_reg_nopen.predict(XX_test)\n",
    "print(\"Regresja bez regularyzacji:\")\n",
    "print(CR(y_test,y_pred_reg_nopen))\n",
    "\n",
    "params = {'C': np.linspace(.01, 100, 100)}\n",
    "reg_prototype = GridSearchCV(lm.LogisticRegression(penalty='l1', solver='liblinear'),params)\n",
    "reg_prototype.fit(XX_train,y_train)\n",
    "C = reg_prototype.best_params_['C']\n",
    "model_reg = lm.LogisticRegression(penalty='l1', C=C, solver='liblinear').fit(XX_train,y_train)\n",
    "y_pred_reg = model_reg.predict(XX_test)\n",
    "print(\"Regresja z regularyzacją:\")\n",
    "print('C:',C)\n",
    "print(CR(y_test,y_pred_reg))\n",
    "\n",
    "#support vector machine--------------------------------------------------------------------------------------\n",
    "params = {\n",
    "    'C': np.linspace(.01, 10, 50),\n",
    "    'gamma': np.linspace(.01, 10, 50)\n",
    "}\n",
    "svm_prototype = GridSearchCV(SVC(kernel='rbf', random_state=0),params)\n",
    "svm_prototype.fit(XX_train,y_train)\n",
    "C = svm_prototype.best_params_['C']\n",
    "gamma = svm_prototype.best_params_['gamma']\n",
    "model_svm = SVC(kernel='rbf', random_state=0, C=C, gamma=gamma).fit(XX_train,y_train)\n",
    "y_pred_svm = model_svm.predict(XX_test)\n",
    "print(\"Maszyna wektorów nośnych:\")\n",
    "print(svm_prototype.best_params_)\n",
    "print(CR(y_test,y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Zadanie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Mając do dyspozycji dane dotyczące cen domów w Bostonie oraz budżet rzędu 20 tys. dolarów, \n",
    "stwórz optymalny model objaśniająycy czy proponowany dom jest w Twoim zasięgu cenowym. \n",
    "Zmienna opisująca ceny zawiera się w \"target\". \n",
    "Całą pracę rozpocznij od oddzielenia losowo wybranych  $20\\%$ danych. Następnie pracuj na pozostałych  $80\\%$  danych. \n",
    "Zdecyduj jak przygotować dane i które zmienne brać pod uwagę. Zdobądź informacje co dostępne zmienne oznaczają. \n",
    "Przy pomocy testowania krzyżowego znajdź najlepsze parametry. \n",
    "Na końcu sprawdź działanie modelu na wcześniej oddzielonych $20\\%$ danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "Regresja bez regularyzacji:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        59\n",
      "           1       0.88      0.88      0.88        43\n",
      "\n",
      "    accuracy                           0.90       102\n",
      "   macro avg       0.90      0.90      0.90       102\n",
      "weighted avg       0.90      0.90      0.90       102\n",
      "\n",
      "Regresja z regularyzacją:\n",
      "C: 3.04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        59\n",
      "           1       0.88      0.88      0.88        43\n",
      "\n",
      "    accuracy                           0.90       102\n",
      "   macro avg       0.90      0.90      0.90       102\n",
      "weighted avg       0.90      0.90      0.90       102\n",
      "\n",
      "Maszyna wektorów nośnych:\n",
      "{'C': 2.4565306122448978, 'gamma': 0.01}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92        59\n",
      "           1       0.90      0.88      0.89        43\n",
      "\n",
      "    accuracy                           0.91       102\n",
      "   macro avg       0.91      0.91      0.91       102\n",
      "weighted avg       0.91      0.91      0.91       102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report as CR\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import datasets\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "print(boston.feature_names)\n",
    "X, y = boston.data, boston.target\n",
    "\n",
    "#CRIM - per capita crime rate by town\n",
    "#ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "#INDUS - proportion of non-retail business acres per town\n",
    "#CHAS - 1 if tract bounds river; 0 otherwise\n",
    "#NOX - nitric oxides concentration\n",
    "#RM - average number of rooms per dwelling\n",
    "#AGE       proportion of owner-occupied units built prior to 1940\n",
    "#DIS       weighted distances to five Boston employment centres\n",
    "#RAD       index of accessibility to radial highways\n",
    "#TAX      full-value property-tax rate per $10,000\n",
    "#PTRATIO  pupil-teacher ratio by town\n",
    "#B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "#LSTAT    % lower status of the population\n",
    "#MEDV     Median value of owner-occupied homes in $1000's\n",
    "\n",
    "yp = []\n",
    "for val in y:\n",
    "    if val<=20:\n",
    "        yp.append(1)\n",
    "    else:\n",
    "        yp.append(0)\n",
    "        \n",
    "y = np.array(yp)\n",
    "XX = X\n",
    "#print(y[:16])\n",
    "#print(yp[:16])\n",
    "\n",
    "XX_train, XX_test, y_train, y_test = train_test_split(XX,y,test_size=.2)\n",
    "XX_train = scale(XX_train)\n",
    "XX_test = scale(XX_test)\n",
    "\n",
    "#regresja logistyczna---------------------------------------------------------------------------------------\n",
    "model_reg_nopen = lm.LogisticRegression(penalty='none').fit(XX_train,y_train)\n",
    "y_pred_reg_nopen = model_reg_nopen.predict(XX_test)\n",
    "print(\"Regresja bez regularyzacji:\")\n",
    "print(CR(y_test,y_pred_reg_nopen))\n",
    "\n",
    "params = {'C': np.linspace(.01, 100, 100)}\n",
    "reg_prototype = GridSearchCV(lm.LogisticRegression(penalty='l1', solver='liblinear'),params)\n",
    "reg_prototype.fit(XX_train,y_train)\n",
    "C = reg_prototype.best_params_['C']\n",
    "model_reg = lm.LogisticRegression(penalty='l1', C=C, solver='liblinear').fit(XX_train,y_train)\n",
    "y_pred_reg = model_reg.predict(XX_test)\n",
    "print(\"Regresja z regularyzacją:\")\n",
    "print('C:',C)\n",
    "print(CR(y_test,y_pred_reg))\n",
    "\n",
    "#support vector machine--------------------------------------------------------------------------------------\n",
    "params = {\n",
    "    'C': np.linspace(.01, 10, 50),\n",
    "    'gamma': np.linspace(.01, 10, 50)\n",
    "}\n",
    "svm_prototype = GridSearchCV(SVC(kernel='rbf', random_state=0),params)\n",
    "svm_prototype.fit(XX_train,y_train)\n",
    "C = svm_prototype.best_params_['C']\n",
    "gamma = svm_prototype.best_params_['gamma']\n",
    "model_svm = SVC(kernel='rbf', random_state=0, C=C, gamma=gamma).fit(XX_train,y_train)\n",
    "y_pred_svm = model_svm.predict(XX_test)\n",
    "print(\"Maszyna wektorów nośnych:\")\n",
    "print(svm_prototype.best_params_)\n",
    "print(CR(y_test,y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
